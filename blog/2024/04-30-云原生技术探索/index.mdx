---
title: 云原生技术探索
authors: [czasg]
tags: [撰写中,待分类]
slug: 云原生技术探索
toc_max_heading_level: 5
---

import FullScreenImage from '@site/src/components/FullScreenImage';
import BrowserWindow from '@site/src/components/BrowserWindow';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<!--package-->

如果在10年前，有人给你做 容器、云原生，Serverless的分享，你肯定会以为这个人是个大忽悠。特别是如果你在当时就有了一定的知识积累，你更可能觉得这些技术，都只不过是“新瓶装旧酒”，不值得过度关注。

但技术的演进，往往就是从 **“看不到 / 看不起” => "看不懂" => "跟不上"**。

但无论现阶段的我们处于那种状态，在当前容器化时代，掌握容器引擎、容器编排管理工具的使用，了解其基础概念与原理，这都将有助于日常工作的开展。

<!--truncate-->

## 1.云计算演进史

:::info 云计算

云计算是通过互联网提供计算资源与服务，用户按需获取，无需拥有硬件，实现灵活、经济高效的计算模式，而无需在本地拥有和维护硬件和软件。

简单来说：云计算是一种服务模式，它通过互联网出租云服务器。

:::

:::info 云原生

CNCF（Cloud Native Computing Foundation，云原生计算基金会）对云原生的定义：云原生技术是有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用技术。其代表技术包括：容器、服务网格、微服务、不可变基础设施和声明式 API 等。

简单来说：云原生是一种软件技术架构，在云计算的基础上，实现了：

- 应用容器化
- 容器编排化（横向扩容、滚动升级、负载均衡、容灾备份等）

:::



### 1.1.虚拟化技术落地

虚拟化技术是一种资源管理技术，在各种实体资源（CPU、内存、网络、存储等）之上构建一个逻辑层，从而摆脱物理限制的约束，提高物理资源的利用率。

- 2001 年 VMware 发布 VMware ESX。它可以在同一台物理机上运行多个虚拟机。这意味着虚拟化技术真正得到了落地，服务器的数量将下降，与之对应的是，服务器资源将得到更加充分的利用。 <br/>
- 2006 年 AWS 首创按时计费的方式租借服务器，揭开了云计算时代帷幕。 <br/>
- 2008 年 Alibaba 开始筹备阿里云，云计算逐渐成为计算机领域最令人关注的话题之一。 <br/>
- 2010 年 openstack 发布第一个开源版本，云计算正式进入开源时代。 <br/>

小结：虚拟化技术 提高了 物理资源的利用率。极大的提升了硬件价值上限。

### 1.2.容器化技术落地

容器化技术同样也是一种资源管理技术，它是在复用系统内核的基础之上，对实体资源（网络、进程、存储等）进一步的构建一个逻辑层。因此相比对虚拟化技术，容器化技术隔离是不彻底的，但更轻量级。

- 2013 年 docker 发布。容器在多数领域逐步替代 VM，云计算进入容器时代。 <br/>
- 2018 年 kubernetes 基本全面赢得容器编排市场的胜利，云计算进入 K8S 时代。 <br/>

小结：容器化技术 建立在 虚拟化技术优势之上，不仅大幅提高了资源的利用率，还提供更轻量级的管理方式。


## 2.云原生代表技术

### 2.1.容器技术（docker）

#### 2.1.1.什么场景下可以使用容器技术?

```
某公司...

研发：服务是否可以直接部署在内部的虚拟机上
组长：可以，但不建议，你们自己部署的服务，没有运维保障，容易背锅
研发：可是我们之前公司都是部署在自己的虚拟机上
组长：你可以把服务构建镜像，然后用容器去跑
研发：没必要啊，我环境都配好了，直接跑不是一样的，性能还更好...
组长：那如果这台虚拟机有问题，你能确保服务快速恢复吗
研发：可以，程序依赖都已经打包好了（jar / venv / static / bin），可以快速重新部署恢复
组长：ojbk

... ...

某天，虚拟机裂开了，研发跑路，运维接坑...
运维：完了，这叼毛 jar 怎么跑不起来，一堆飘红额...
运维：完了，这叼毛 php 是跑起来了还是没跑起来...

... ...
```

上述场景，粗看是一个技术壁垒问题。本质应该还是一个管理问题（交接文档没有写清楚，部署说明没有介绍清楚等...）。 <br/>
但是，这个案列又非常经典，因为技术壁垒导致的项目管理复杂度上升，是非常常见的。 <br/>
特别是对一些交付源码的项目，这种项目往往高度依赖环境准备... <br/>

如果有一种技术，它可以定义一种通用的交付产物，消除研发、测试、运维、产品之间的强技术壁垒，并在整个项目生命周期内达成一种通用的“语言”。那这个技术，简直泰裤辣。

而 docker，就是这么一门技术。 <br/>
它创新性的引入了镜像概念，重新定义了交付产物，让不同的服务之间，可以以近乎相似的方式进行维护。 <br/>
也正是因为镜像的引入，彻底掀起了容器化的热潮~ <br/>

答案：除了不能用使用容器的场景，否则都推荐使用容器技术~



#### 2.1.2.一个简单的容器场景

场景：前端编译后需要对外发布

```python title="1-编译镜像"
### 镜像拉取
> docker pull nginx:latest

### 镜像模板
> vim Dockerfile
1. FROM nginx:latest
2.
3. COPY ./dist/ /usr/share/nginx/html/
4. EXPOSE 80

### 编译镜像
> docker build -t harbor.avlyun.org/developer-center/web-fe:latest .
```

```python title="2-推送镜像"
### 登录镜像仓库
> docker login harbor.avlyun.org

### 推送镜像
> docker push harbor.avlyun.org/developer-center/web-fe:latest
```

```python title="3-运行容器"
### 登录远程服务
> ssh xx.xx.xx.xx

### 拉取镜像
> docker pull harbor.avlyun.org/developer-center/web-fe:latest

### 启动服务
> docker run -itd --name web-fe -p 80:80 harbor.avlyun.org/developer-center/web-fe:latest
```

#### 2.1.3.容器核心技术
- cgroups：可以控制进程资源的使用。如：CPU、内存 等。
- namespace：可以控制进程资源的隔离。如：网络、存储 等。
- unionfs：可以将多个目录联合挂载到一个统一的目录。（可以简单认为是一种只读的软链接）

#### 2.1.4.docker核心概念
- 镜像
- 网络
- 存储卷

##### 2.1.4.1.镜像

镜像是构建和运行容器的基础。我们可以把镜像理解为一个只读的模板，或者是压缩包，它包含了运行一个应用程序所需要的所有内容：

- 应用程序（源码/编译产物）
- 运行时环境
- 系统工具
- 三方库依赖
- 配置参数
- ... ...

我们完全可以把镜像理解为一个独立且完整的应用程序包。

思考：镜像和之前所提到的交付产物有何区别。

镜像由一系列的层组成，每个层都代表着镜像的一部分。这些层在构建镜像时按照顺序添加，并且都是只读的，因此在构建相同层时可以复用，从而节省存储空间。

<FullScreenImage src={require("./image-layer.jpg").default} />

自己构建一个镜像

```dockerfile
FROM ubuntu:15.04

mkdir /workplace

echo -n > /workplace/README.md
```

<FullScreenImage src={require("./image-layer-2.png").default} />

镜像最终会通过类似一种堆积木的方式呈现出来。从技术角度来讲，这是通过联合文件系统实现的。

<FullScreenImage src={require("./image-layer-3.png").default} />


##### 2.1.4.2.网络

在 docker 中，网络是一种用于容器间通信的机制。在同一个虚拟网络下，不同容器之间是可以相互访问的。

<FullScreenImage src={require("./network.png").default} />

为了确保容器所处网络环境隔离性，可以通过自定义虚拟网络来实现。

```python
# 创建网络network1和network2
docker network create network1
docker network create network2

# 在network1中创建容器container1
docker run -d --name container1 --network network1 your_image

# 在network2中创建容器container2
docker run -d --name container2 --network network2 your_image
```

<FullScreenImage src={require("./network-1.png").default} />

为了进一步的实现网络资源共享，可以通过网络连接的方式，将多容器连接到某一个容器，从而复用指定容器的网络（IP）资源。

```python
# 创建网络network1
docker network create network1

# 在network1中创建容器container1
docker run -d --name container1 --network network1 your_image

# 在network1中创建容器container2、container3，并连接到container1
docker run -d --name container2 --network=container:container1 your_image
docker run -d --name container3 --network=container:container1 your_image
```

<FullScreenImage src={require("./network-2.png").default} />

##### 2.1.4.3.存储卷

在 docker 中，存储卷是一种特殊的文件目录或者文件，用于在容器和宿主机之间实现持久化存储数据。

和镜像层的只读层不同的是，存储卷拥有：

- 持久化的
- 共享的
- 独立于容器生命周期的

```
# -v
docker run -v /host/path:/container/path my_image

# --mount
docker run --mount type=bind,source=/host/path,target=/container/path my_image
```

### 2.2.容器编排技术

容器编排技术本质就是管理容器的技术。

为什么需要使用容器编排技术，容器编排和容器之间的关系，就类似 虚拟机 和 openstack 之间的关系，对于大型容器集群，需要有便捷的工具来管理。

#### 2.2.1.k8s集群架构
k8s 就是目前市面上最成功的容器编排实现标准。

它是经典的主从架构，分别是：contaol-plane 和 node。

|归属|服务|说明|
|---|---|---|
|control-plane|kube-api-server|k8s 网关服务，用于接收所有 k8s 请求并进行处理|
|control-plane|kube-controller-manager|k8s 控制器，负责监控系统状态与变化，确保目标状态符合期望状态|
|control-plane|kube-scheduler|k8s 调度器，统筹所有节点资源，负责和节点交互，并基于一定的规则（亲和性、反亲和性）进行资源调度|
|control-plane|etcd|分布式键值对存储系统|
|node|kubectl|节点上的代理服务，负责该节点的运行状态、容器管理等|
|node|kube-proxy|维护该节点上的网络规则，以确保服务能够被正确发现|
|node|container-runtime|容器引擎，负责容器管理，包括：创建、删除等|
|node|pod|k8s 集群中最小的可部署单元。也是集群中单服务的高层抽象|

我们可以通过熟悉 k8s 的交互流程来熟悉 k8s 架构。下面演示一次完整的 `kubectl apply -f deploy.yaml` 执行流程。

<FullScreenImage src={require("./k8s.png").default} />


#### 3.2.2.pod详解

如果 k8s 是以 docker 作为容器引擎，那么我们完全可以在本地通过 docker 模拟出 pod 的行为。

<BrowserWindow>
    <Tabs>
        <TabItem value="pod" label="Pod" default>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
```

        </TabItem>
        <TabItem value="docker-compose" label="DockerCompose">

```yaml
version: '3'
services:
  nginx:
    image: nginx:latest
    ports:
      - "80:80"
```

        </TabItem>
    </Tabs>
</BrowserWindow>

对于简单场景下的单容器 Pod 来说，k8s 和 docker 部署的服务几乎没有任何区别。

但是，在多容器场景下，Pod 对外表现出来的更像是一个整体，因为他们对外只有一个 IP ~

<BrowserWindow>
    <Tabs>
        <TabItem value="pod-2" label="Pod" default>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
  - name: server
    image: server:latest
    ports:
    - containerPort: 8080
```

        </TabItem>
        <TabItem value="docker-compose-2" label="DockerCompose">

```yaml
version: '3'
services:
  nginx:
    image: nginx:latest
    ports:
      - "80:80"
  server:
    image: server:latest
    ports:
      - "8080:8080"
```

        </TabItem>
        <TabItem value="cmd" label="CMD">

```yaml
docker create network pod

docker run -d --name pause --network=pod pause:latest

docker run -d --name nginx --network=container:pause nginx:latest
docker run -d --name server --network=container:pause server:latest
```

        </TabItem>
    </Tabs>
</BrowserWindow>

对于这种场景下，我们可以通过容器连接来实现，但问题是，以谁为根容器作为被其他容器连接的对象呢？

PS：根容器的特点：稳定

Pod 详解

<FullScreenImage src={require("./k8s-2.png").default} />

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  initContainers:  # 初始化容器列表
  - name: init-container
    image: busybox
    command: ['sh', '-c', 'echo Initializing... && sleep 5']  # 执行初始化操作，输出消息并休眠5秒钟
  containers:  # 主容器列表
  - name: nginx-container
    image: nginx
    lifecycle:  # 定义容器的生命周期钩子
      postStart:
        exec:
          command: ["/bin/sh", "-c", "echo Container started."]  # 在容器启动后执行的命令
      preStop:
        exec:
          command: ["/bin/sh", "-c", "echo Container stopping..."]  # 在容器停止前执行的命令
    readinessProbe:  # 就绪性检查
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5  # 容器启动后等待5秒再进行第一次检查
      periodSeconds: 5  # 间隔5秒进行一次检查
    livenessProbe:  # 存活性检查
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10  # 容器启动后等待10秒再进行第一次检查
      periodSeconds: 5  # 间隔5秒进行一次检查
    volumeMounts:  # 容器的挂载点
    - name: shared-data
      mountPath: /usr/share/nginx/html  # 将 emptyDir 卷挂载到容器的 /usr/share/nginx/html 路径，实现数据共享
  volumes:  # 卷列表
  - name: shared-data
    emptyDir: {}  # 空目录卷，用于在 init-container 和主容器之间共享数据
  restartPolicy: Always  # 容器的重启策略，始终重启
```

#### 3.2.3.常用资源对象介绍
在 k8s 集群中，一般不直接使用 pod。因为 pod 的生命周期被视为短暂的~

为了更好的去管理集群中的 pod 应用，k8s 集群引入了其他的资源对象。

|资源对象|说明|其他|
|---|---|---|
|Deployment||
|Service|一组服务的抽象|dns|
|Ingress|路由规则集，用于控制集群外部流量导入|nginx|
|ConfigMap|配置中心||

<FullScreenImage src={require("./k8s-3.png").default} />

##### 3.2.3.1.configmap
configmap 是键值对配置，可以以环境变量或者文件的形式注入进 pod。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx
data:
  LOG_LEVEL: debug
  LOG_FORMAT: json
  NGINX_CONFIG_FILE: |-
    server {
        listen       80;
        server_name  localhost;
        location / {
            root   /usr/share/nginx/html;
            index  index.html index.htm;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   /usr/share/nginx/html;
        }
    }
---
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
    envFrom: # 指定环境变量来源于configMap
    - configMapRef:
        name: nginx
    env: # 直接在pod中指定需要哪些环境变量，此优先级最高
    - name: "LOG_LEVEL"
        value: "error"
    - name: "LOG_FORMAT"
        value: "text"
    volumeMounts: # 通过文件的形式注入pod
    - mountPath: /etc/nginx/conf.d/
      name: nginx-conf-file
  volumes:
  - configMap: # 指定存储卷类型为configMap
      defaultMode: 420
      items:
      - key: NGINX_CONFIG_FILE # 仅取出其中某个key
        path: default.conf
      name: nginx-conf-file
```

##### 3.2.3.2.ingress

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: nginx
spec:
  rules:
    - host: nginx.hsk8s-dev.avlyun.org
      http:
        paths:
          - path: /download
            backend:
              serviceName: nginx
              servicePort: 80
          - path: /api/v1
            backend:
              serviceName: server-v1
              servicePort: 80
          - path: /api/v2
            backend:
              serviceName: server-v2
              servicePort: 80
```

##### 3.2.3.3.service
service 是一组服务的抽象，可用于 DNS 解析，其解析的结果，是对应 Pod 的 IP 集合。

因此，我们完全可以把 service 当做一个合法的域名来使用。下面通过执行 `curl nginx.fos-2-dev` 来展示 service 的魅力~

<FullScreenImage src={require("./service.png").default} />

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  ports: # 定义一组服务中的端口转发
  - name: nginx
    port: 80
    protocol: TCP
    targetPort: 80
  selector: # 定义一组服务（pod）标签
    app: nginx
  type: ClusterIP
```

问题：在 k8s 集群中，到底应该如何访问其他服务？

答案：应该通过 service.namespace 来访问，直接端到端的跑流量，而不用走 ingress 转发。

##### 3.2.3.1.deployment

<BrowserWindow>
    <Tabs>
        <TabItem value="pod-3" label="Pod" default>

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:latest
    ports:
    - containerPort: 80
```

        </TabItem>
        <TabItem value="deployment-rollingUpdate" label="Deployment/RollingUpdate">

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3  # 副本数为 3
  selector:
    matchLabels:
      app: nginx
  strategy:
    rollingUpdate:
      maxSurge: 50%  # 允许的最大超出副本数，支持整数，也支持百分比
      maxUnavailable: 1  # 允许的最大不可用副本数，支持整数，也支持百分比
    type: RollingUpdate  # 使用滚动升级策略
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest  # 使用最新版本的 Nginx 镜像
        ports:
        - containerPort: 80  # 容器监听端口 80
```

        </TabItem>
        <TabItem value="deployment-recreate" label="Deployment/Recreate">

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3  # 副本数为 3
  selector:
    matchLabels:
      app: nginx
  strategy:
    type: Recreate # 使用重建升级策略
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest  # 使用最新版本的 Nginx 镜像
        ports:
        - containerPort: 80  # 容器监听端口 80
```

        </TabItem>
    </Tabs>
</BrowserWindow>


## 4.答疑
... ...







<br/>

:::info 👇👇👇
**本文作者:** 橙子昂 <br/>
**版权声明:** 转载请注明出处哦~👮‍👮‍👮‍
:::
